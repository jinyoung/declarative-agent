# API Keys (Required)
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
TAVILY_API_KEY=your_tavily_api_key

# LLM Configuration
MODEL_PROVIDER=openai        # Options: openai, anthropic
MODEL_NAME=gpt-4             # For OpenAI: gpt-4, gpt-3.5-turbo | For Anthropic: claude-3, etc.
TEMPERATURE=0.0              # Temperature for model responses (0.0-1.0)

# Vector Database Configuration (if using)
VECTORDB_TYPE=faiss          # Options: faiss, pinecone, etc.
VECTORDB_PATH=./vectordb     # Path to local vector database (for FAISS)

# Graph Database Configuration (if using)
GRAPHDB_URI=bolt://localhost:7687
GRAPHDB_USERNAME=neo4j
GRAPHDB_PASSWORD=password

# Application Settings
DEBUG=false
LOG_LEVEL=info               # Options: debug, info, warn, error
PORT=8000                    # API server port

# Optional - defaults shown
MODEL=claude-3-7-sonnet-20250219  # Recommended models: claude-3-7-sonnet-20250219, claude-3-opus-20240229 (Required)
PERPLEXITY_MODEL=sonar-pro        # Make sure you have access to sonar-pro otherwise you can use sonar regular (Optional)
MAX_TOKENS=64000                   # Maximum tokens for model responses (Required)
TEMPERATURE=0.2                   # Temperature for model responses (0.0-1.0) - lower = less creativity and follow your prompt closely (Required)
DEBUG=false                       # Enable debug logging (true/false)
LOG_LEVEL=info                    # Log level (debug, info, warn, error)
DEFAULT_SUBTASKS=5                # Default number of subtasks when expanding
DEFAULT_PRIORITY=medium           # Default priority for generated tasks (high, medium, low)
PROJECT_NAME={{projectName}}      # Project name for tasks.json metadata